# -*- coding: utf-8 -*-
"""SIstem Cerdas_GoogleNet_Kanker Serviks.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zYnMjaiB00nph5o5Y2HiSmCwQuMgKJPK

## ***KLASIFIKASI KANKER SERVIKS DARI CITRA PAP-SMEAR BERBASIS ARSITEKTUR GOOGLENET CONVOLUTIONAL NEURAL NETWORK (CNN)***

Pembuatan project tersebut sebagai pemenuhan project akhir Ujian Akhir Semester pada mata kuliah Sistem Cerdas 2022.

## ***Nama Kelompok*** 
1. Eka Maria Sidauruk   (081911733009)
2. Mustikaningrum       (081911733010)
3. Arel Maratun Nadiroh (081911733015)
4. Melyna Wahyudi       (081911733017)
5. Winanda Reza Aulia   (081911733019)
"""

from google.colab import drive
drive.mount('/content/drive')

"""## ***Data Acquisition***"""

import numpy as np # linear algebra
import pandas as pd

import os
for dirname, _, filenames in os.walk('/content/drive/MyDrive/Dataset/dataset_smear'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

import torch
import torch.nn.functional as F
import torchvision
from torchvision import datasets,transforms
from torch import nn
import matplotlib.pyplot as plt
import numpy as np
import torchvision.models as models
from torch import tensor

"""## ***Data Exploration***"""

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

IMGSIZE = 90
transform1 = transforms.Compose([transforms.RandomHorizontalFlip(),
                                transforms.RandomRotation(0.2),
                                transforms.ToTensor(),
                                transforms.Resize((IMGSIZE,IMGSIZE))
                               ])

full_data = torchvision.datasets.ImageFolder(root = '/content/drive/MyDrive/Dataset/dataset_smear', transform = transform1)

len(full_data)

classes = full_data.classes
print("Classes:",classes)
num_classes = len(full_data.classes)
print("Number of Classes:",num_classes)

train_data, test_data = torch.utils.data.random_split(full_data, [747, 187])  # In 80% & 20% ratio

train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size = 46, shuffle = True)

test_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size = 46, shuffle = True)

def normalize_image(image):
    image_min = image.min()
    image_max = image.max()
    image.clamp_(min = image_min, max = image_max)
    image.add_(-image_min).div_(image_max - image_min + 1e-5)
    return image

def plot_images(images, labels, classes, normalize = True):

    n_images = len(images)

    rows = int(np.sqrt(n_images))
    cols = int(np.sqrt(n_images))

    fig = plt.figure(figsize = (10, 10))

    for i in range(rows*cols):

        ax = fig.add_subplot(rows, cols, i+1)
        
        image = images[i]

        if normalize:
            image = normalize_image(image)

        ax.imshow(image.permute(1, 2, 0).cpu().numpy() )
        ax.set_title(classes[labels[i]])
        ax.axis('off')

N_IMAGES = 9

images, labels = zip(*[(image, label) for image, label in [train_data[i] for i in range(N_IMAGES)]])

classes = full_data.classes

plot_images(images, labels, classes)

"""## ***Modelling -- GoogleNet***"""

googlenet = models.googlenet(pretrained=True)

print(googlenet)

# Specify model architecture
# Load the pretrained model from pytorch's library and stored it in model_transfer
model_transfer = models.googlenet(pretrained=True)

# Check if GPU is available
use_cuda = torch.cuda.is_available()
if use_cuda:
    model_transfer = model_transfer.cuda()

#Lets read the fully connected layer
print(model_transfer.fc.in_features)
print(model_transfer.fc.out_features)

for param in model_transfer.parameters():
    param.requires_grad=True

# Define n_inputs takes the same number of inputs from pre-trained model
n_inputs = model_transfer.fc.in_features #refer to the fully connected layer only

# New layer automatically has requires_grad = True
last_layer = nn.Linear(n_inputs, len(classes))

model_transfer.fc = last_layer

# If GPU is available, move the model to GPU
if use_cuda:
    model_transfer = model_transfer.cuda()
  
# Check to see the last layer produces the expected number of outputs
print(model_transfer.fc.out_features)

# Specify loss function and optimizer
criter = nn.CrossEntropyLoss()
optimz = torch.optim.Adam(googlenet.parameters(),lr=1e-5,weight_decay=1e-5)

TrainLoss = []
TrainAcc = []
TestLoss = []
TestAcc = []
num_epochs = 100

# Train the model
total_step = len(train_loader)

for epoch in range(num_epochs):
    trainAcc = 0
    testAcc = 0
    for i, (images, labels) in enumerate(train_loader):
        googlenet.train()
        images = images.to(device)
        labels = labels.to(device)
        
        # Forward pass
        outputs = googlenet(images)
        trainloss = criter(outputs, labels)
        
        # Backward and optimize
        optimz.zero_grad()
        trainloss.backward()
        optimz.step()
        
        # Checking accuracy
        preds = outputs.data.max(dim=1,keepdim=True)[1]
        trainAcc += preds.eq(labels.data.view_as(preds)).cpu().sum()
    
    trainAcc = trainAcc/len(train_loader.dataset) * 100
    
    for i, (images, labels) in enumerate(test_loader):
        googlenet.eval()
        images = images.to(device)
        labels = labels.to(device)
    
        # Forward pass
        outputs = googlenet(images)
        testloss = criter(outputs, labels)
    
        # Checking accuracy
        preds = outputs.data.max(dim=1,keepdim=True)[1]
        testAcc += preds.eq(labels.data.view_as(preds)).cpu().sum()
    
    testAcc = testAcc/len(test_loader.dataset) * 100
    
    print("Epoch {} =>  Train Loss : {trainloss:.2f};   Train Accuracy : {trainAcc:.2f}%;   Test Loss : {testloss:.2f};   Test Accuracy : {testAcc:.2f}%".format(epoch+1, trainloss=trainloss.item(), trainAcc=trainAcc, testloss=testloss.item(), testAcc=testAcc))
  
    TrainLoss.append(trainloss)
    TrainAcc.append(trainAcc)

    TestLoss.append(testloss)
    TestAcc.append(testAcc)

# Save the model checkpoint
torch.save(googlenet.state_dict(), 'GoogleNetModel.ckpt')

"""## ***Evaluation***"""

plt.plot(range(100),TrainAcc)
plt.plot(range(100),TestAcc)
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.title("Accuracy of GoogleNet")
plt.legend(["Training Accuracy", "Testing Accuracy"])
plt.show()

with torch.no_grad():
    plt.plot(range(100),TrainLoss)
    plt.plot(range(100),TestLoss)
    plt.ylabel('Loss')
    plt.xlabel('Epoch')
    plt.title("Loss of GoogleNet")
    plt.legend(["Training Loss", "Testing Loss"])
    plt.show()